{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c327781-f86b-4ef3-b8ae-06d15cefc3d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1. Bag of Words technique - (BOW)\n",
    "To represent the text in Count format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a644cda4-9d99-4080-ac80-ac0ea43ed4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cat sat on the mat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dog chased the cat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The dog sat on the mat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The cat played with the dog.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The bird flew over the cat and dog.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  text\n",
       "0              The cat sat on the mat.\n",
       "1              The dog chased the cat.\n",
       "2              The dog sat on the mat.\n",
       "3         The cat played with the dog.\n",
       "4  The bird flew over the cat and dog."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample text data\n",
    "data = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"The dog chased the cat.\",\n",
    "    \"The dog sat on the mat.\",\n",
    "    \"The cat played with the dog.\",\n",
    "    \"The bird flew over the cat and dog.\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "columns = ['text']\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9621735c-deb8-430c-a03b-611ca77ab334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "bow = cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6edd5959-b893-4ef4-a982-9b717f0ee8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 2, 0],\n",
       "       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 2, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 2, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 2, 1],\n",
       "       [1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 2, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3398ee0b-7691-4135-90a1-f205819e3732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 11, 'cat': 2, 'sat': 10, 'on': 7, 'mat': 6, 'dog': 4, 'chased': 3, 'played': 9, 'with': 12, 'bird': 1, 'flew': 5, 'over': 8, 'and': 0}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42a7e52-1ba8-4aba-a6ed-4d1ec7a06ddf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2. NGrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692ddf7-98fc-41fa-96f8-21a1973381d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2. BiGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fe4281c-4ef4-4c13-9367-50b49d672d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the cat': 14, 'cat sat': 4, 'sat on': 12, 'on the': 9, 'the mat': 16, 'the dog': 15, 'dog chased': 6, 'chased the': 5, 'dog sat': 7, 'cat played': 3, 'played with': 11, 'with the': 17, 'the bird': 13, 'bird flew': 1, 'flew over': 8, 'over the': 10, 'cat and': 2, 'and dog': 0}\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(2,2))\n",
    "bow2 = cv.fit_transform(df['text'])\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7925f88e-df99-48cc-836e-b0fd1beef703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1],\n",
       "       [1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow2.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecec794-0335-4ea1-b170-75edd2f07a6d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2.b TriGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2de401b1-f2ca-4760-9133-ffeba29574ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the cat sat': 15, 'cat sat on': 3, 'sat on the': 11, 'on the mat': 8, 'the dog chased': 16, 'dog chased the': 5, 'chased the cat': 4, 'the dog sat': 17, 'dog sat on': 6, 'the cat played': 14, 'cat played with': 2, 'played with the': 10, 'with the dog': 18, 'the bird flew': 12, 'bird flew over': 0, 'flew over the': 7, 'over the cat': 9, 'the cat and': 13, 'cat and dog': 1}\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(3,3))\n",
    "bow3 = cv.fit_transform(df['text'])\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28f2dc87-069f-45c7-b18c-529304411149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow3.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33e8fb7-09c6-438b-a26b-ce1d4ce12a6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3. TF-IDF (Term Frequency - Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63634a94-b779-448c-a261-0937602fe130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF = TF * IDF\n",
    "# TF = How many times a word in coming in the current document)\n",
    "# IDF = log \n",
    "    # (\n",
    "    # Total number of documents\n",
    "    #           / \n",
    "    # Number of time Word is coming in all the documents \n",
    "    # )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebe00a31-aedc-423d-b072-c70d97e92fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.31600987, 0.        , 0.        ,\n",
       "        0.        , 0.4525429 , 0.4525429 , 0.        , 0.        ,\n",
       "        0.4525429 , 0.53455825, 0.        ],\n",
       "       [0.        , 0.        , 0.35328705, 0.62708198, 0.35328705,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.59761585, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.31600987,\n",
       "        0.        , 0.4525429 , 0.4525429 , 0.        , 0.        ,\n",
       "        0.4525429 , 0.53455825, 0.        ],\n",
       "       [0.        , 0.        , 0.29930642, 0.        , 0.29930642,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.53126675,\n",
       "        0.        , 0.5063029 , 0.53126675],\n",
       "       [0.42474318, 0.42474318, 0.2392929 , 0.        , 0.2392929 ,\n",
       "        0.42474318, 0.        , 0.        , 0.42474318, 0.        ,\n",
       "        0.        , 0.4047848 , 0.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "arr = tfidf.fit_transform(df['text']).toarray()\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4863db9-b815-4b6b-a1bb-1574a5a161f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 11, 'cat': 2, 'sat': 10, 'on': 7, 'mat': 6, 'dog': 4, 'chased': 3, 'played': 9, 'with': 12, 'bird': 1, 'flew': 5, 'over': 8, 'and': 0}\n",
      "[2.09861229 2.09861229 1.18232156 2.09861229 1.18232156 2.09861229\n",
      " 1.69314718 1.69314718 2.09861229 2.09861229 1.69314718 1.\n",
      " 2.09861229]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.vocabulary_, tfidf.idf_, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4e2e16-2396-423d-b1a0-928f280625fc",
   "metadata": {},
   "source": [
    "#### 4. Word2Vec Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3cf3a5bb-2abb-4b62-a07b-af4df40846d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import gensim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b75c1c2-70e0-40e4-8361-ce71a485bfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/de-ninja/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0bd1f255-1524-4311-a6d7-ab54f62b200c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/de-ninja/Documents/Courses/Gen-AI-freecodecamp'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "93ab6035-a69e-463a-9813-c38e17375fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = []\n",
    "for file in os.listdir('GOT books'):\n",
    "    if file == \".ipynb_checkpoints\":\n",
    "        pass\n",
    "    else:\n",
    "        f = open(os.path.join('GOT books', file), encoding='unicode_escape')\n",
    "        corpus = f.read()\n",
    "        # print(f)\n",
    "        tokens = sent_tokenize(corpus)\n",
    "        for token in tokens:\n",
    "            story.append(simple_preprocess(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c5353c7-89df-41a3-a480-4833511e4b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6569866, 8628190)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window = 10,\n",
    "    min_count = 2 \n",
    ")\n",
    "model.build_vocab(story)\n",
    "model.train(story, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1fb279a5-4126-4e46-8ac4-d21ce82e2906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tyrion', 0.8551657795906067),\n",
       " ('cersei', 0.7381189465522766),\n",
       " ('davos', 0.6893479228019714),\n",
       " ('brienne', 0.6819226741790771),\n",
       " ('ned', 0.6742334961891174),\n",
       " ('littlefinger', 0.6327482461929321),\n",
       " ('theon', 0.6226832866668701),\n",
       " ('bronn', 0.6183401346206665),\n",
       " ('hound', 0.6157232522964478),\n",
       " ('catelyn', 0.6154235005378723)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('jaime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "48c29a5d-65eb-4a9e-89d9-cd3646d8be93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85418594"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('arya', 'sansa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f295fb2-dd69-429e-8c9e-4639dd763a43",
   "metadata": {},
   "source": [
    "##### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "23edf774-7e4a-40ec-bc94-8c55e15fc9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "X = pca.fit_transform(model.wv.get_normed_vectors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ac184c26-a2fa-4875-972b-f9d375b40f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13593999, -0.5969083 ,  0.03683241],\n",
       "       [ 0.17027196, -0.33013898, -0.05908604],\n",
       "       [-0.29053146, -0.5784489 , -0.20001513],\n",
       "       ...,\n",
       "       [-0.4151773 , -0.08914551, -0.18182142],\n",
       "       [-0.02611536,  0.09978819,  0.05820008],\n",
       "       [-0.10088348,  0.22486311,  0.16903715]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d99f6b28-9424-478e-8a25-830d6697e139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17453, 3)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f6f2fa09-3454-407e-863e-26b21935cb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17027196, -0.33013898, -0.05908604], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:4][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8033379c-25a9-4a80-8ea4-885ba12615f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import split, split_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "04f8bedc-559a-4ade-a6cc-e97f9c1cac3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/18 21:50:48 WARN Utils: Your hostname, codebase resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/11/18 21:50:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/18 21:50:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/18 21:51:08 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('test').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1ba40581-b58a-458f-9d38-94622033234c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/18 21:52:43 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1: Division ID and Amount\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "| Division_ID|Amount|\n",
      "+------------+------+\n",
      "|DIV-NY_12345|   500|\n",
      "|DIV-LA_67890|   300|\n",
      "|DIV-SF_11223|   800|\n",
      "|DIV-NY_54321|   200|\n",
      "|DIV-LA_98765|   100|\n",
      "+------------+------+\n",
      "\n",
      "Table 2: City Abbreviation and Full Location Name\n",
      "+-----------------+------------------+\n",
      "|City_Abbreviation|Full_Location_Name|\n",
      "+-----------------+------------------+\n",
      "|               NY|          New York|\n",
      "|               LA|       Los Angeles|\n",
      "|               SF|     San Francisco|\n",
      "+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"CreateTables\").getOrCreate()\n",
    "\n",
    "# Data for the first table\n",
    "data1 = [\n",
    "    (\"DIV-NY_12345\", 500),\n",
    "    (\"DIV-LA_67890\", 300),\n",
    "    (\"DIV-SF_11223\", 800),\n",
    "    (\"DIV-NY_54321\", 200),\n",
    "    (\"DIV-LA_98765\", 100),\n",
    "]\n",
    "\n",
    "schema1 = StructType([\n",
    "    StructField(\"Division_ID\", StringType(), True),\n",
    "    StructField(\"Amount\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "df1 = spark.createDataFrame(data1, schema=schema1)\n",
    "\n",
    "# Data for the second table\n",
    "data2 = [\n",
    "    (\"NY\", \"New York\"),\n",
    "    (\"LA\", \"Los Angeles\"),\n",
    "    (\"SF\", \"San Francisco\"),\n",
    "]\n",
    "\n",
    "schema2 = StructType([\n",
    "    StructField(\"City_Abbreviation\", StringType(), True),\n",
    "    StructField(\"Full_Location_Name\", StringType(), True),\n",
    "])\n",
    "\n",
    "df2 = spark.createDataFrame(data2, schema=schema2)\n",
    "\n",
    "# Show the data\n",
    "print(\"Table 1: Division ID and Amount\")\n",
    "df1.show()\n",
    "\n",
    "print(\"Table 2: City Abbreviation and Full Location Name\")\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "646c45c9-9c1d-41c3-b78d-d2cd17b5fed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+---+\n",
      "| Division_ID|Amount|key|\n",
      "+------------+------+---+\n",
      "|DIV-NY_12345|   500| NY|\n",
      "|DIV-LA_67890|   300| LA|\n",
      "|DIV-SF_11223|   800| SF|\n",
      "|DIV-NY_54321|   200| NY|\n",
      "|DIV-LA_98765|   100| LA|\n",
      "+------------+------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:==============================================>         (10 + 2) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+-----------------+------------------+\n",
      "| Division_ID|Amount|City_Abbreviation|Full_Location_Name|\n",
      "+------------+------+-----------------+------------------+\n",
      "|DIV-LA_67890|   300|               LA|       Los Angeles|\n",
      "|DIV-LA_98765|   100|               LA|       Los Angeles|\n",
      "|DIV-NY_12345|   500|               NY|          New York|\n",
      "|DIV-NY_54321|   200|               NY|          New York|\n",
      "|DIV-SF_11223|   800|               SF|     San Francisco|\n",
      "+------------+------+-----------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df1.withColumn('key', split(split(\"Division_ID\",'-')[1], \"_\")[0]).show()\n",
    "df1.join(df2, split(split(df1[\"Division_ID\"],'-')[1], \"_\")[0] == df2['City_Abbreviation'], 'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6d64d52c-1341-4a6c-be72-ed4f2b2bd6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView('df1')\n",
    "df2.createOrReplaceTempView('df2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "877aec54-7b7f-4d11-9531-8815c9d89888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:==============>                                          (3 + 9) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+------------------+\n",
      "|Division_ID |Amount|full_location_name|\n",
      "+------------+------+------------------+\n",
      "|DIV-NY_12345|500   |New York          |\n",
      "|DIV-LA_67890|300   |Los Angeles       |\n",
      "|DIV-SF_11223|800   |San Francisco     |\n",
      "|DIV-NY_54321|200   |New York          |\n",
      "|DIV-LA_98765|100   |Los Angeles       |\n",
      "+------------+------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT a.*, b.full_location_name FROM df1 a \n",
    "    LEFT JOIN df2 b \n",
    "    ON substr(a.Division_ID, 5, LENGTH(a.Division_ID) - 10) = b.City_Abbreviation\n",
    "    \"\"\"\n",
    ").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d21d22-ec4d-4d67-b6b2-9b4c3f2739dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
