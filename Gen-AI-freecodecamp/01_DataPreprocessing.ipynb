{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d7578d-32e9-41a8-b5c7-978ee2c79ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/de-ninja/airflow-venv/lib/python3.10/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /home/de-ninja/airflow-venv/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/de-ninja/airflow-venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/de-ninja/airflow-venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/de-ninja/airflow-venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/de-ninja/airflow-venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6712c96f-6256-41b2-97da-4b191b393e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da62b4b-bccf-4993-8ea2-4ba6b4f7c276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/de-ninja/airflow-venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 25.7M/25.7M [00:03<00:00, 7.65MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/de-ninja/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bca2d9c-12a7-49b9-a404-0940c2aaabe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path+'/IMDB Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52ac8254-1120-46bc-b09c-a2280d8812c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3990/2044023174.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df.loc[1][0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778bdc2f-9cbe-48f8-93c0-d900caaedab5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1. Removing HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e443a75d-a2c3-4275-aa79-a78047de65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile(\"<.*?>\")\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24518a7f-cda9-4d3d-a155-4fe58acbfab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f771b6a-6248-4791-acf4-b82d049dd7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. The filming tec...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86b856a-01ec-4398-8837-a67bb96bbe2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2. Removing URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9b07d56-02ab-48d9-93a1-e88530cbc778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    pattern = re.compile(r'https?://\\S+')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fde6489-099d-41f0-bab4-e2a017d4082d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. The filming tec...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(remove_urls)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd96b611-3d5d-414d-8666-270ff92c72f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3. Puntuation Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "faa6efe5-6da6-4bef-a5f8-934d578f6847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string, time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7910fb2f-e102-42d3-9055-5b3a5aed9f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is Rohit Kumar, an AI enthusiast. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df5df991-93bb-4afb-8dcf-2b173031f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    for i in text:\n",
    "        if i in string.punctuation:\n",
    "            text = text.replace(i, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1aeec10b-aff8-48a3-9c47-8fafbe1f97d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.524785280227661"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "# remove_punctuations(text)\n",
    "df['review'] = df['review'].apply(remove_punctuations)\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1f7159f-3b32-47f6-bed9-ce53cf03cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations_v2(text):\n",
    "    return text.translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f90e0ec5-188b-441a-b71d-419b5753945a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7560343742370605"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "# remove_punctuations(text)\n",
    "df['review'] = df['review'].apply(remove_punctuations_v2)\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a493dd83-3a5d-4f2a-a423-6dcda2e71d42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 4. Chat Abbreviations Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "347d39c7-5bff-4d39-a6a2-c7179fbfc4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_abbreviations = {\n",
    "    \"AFK\": \"Away From Keyboard\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"DM\": \"Direct Message\",\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"GG\": \"Good Game\",\n",
    "    \"GLHF\": \"Good Luck, Have Fun\",\n",
    "    \"IDK\": \"I Don’t Know\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"IMHO\": \"In My Humble Opinion\",\n",
    "    \"IRL\": \"In Real Life\",\n",
    "    \"LMAO\": \"Laughing My Ass Off\",\n",
    "    \"LOL\": \"Laugh Out Loud\",\n",
    "    \"NP\": \"No Problem\",\n",
    "    \"NSFW\": \"Not Safe For Work\",\n",
    "    \"OMG\": \"Oh My God\",\n",
    "    \"OMW\": \"On My Way\",\n",
    "    \"ROFL\": \"Rolling On Floor Laughing\",\n",
    "    \"SMH\": \"Shaking My Head\",\n",
    "    \"TBH\": \"To Be Honest\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"TY\": \"Thank You\",\n",
    "    \"YOLO\": \"You Only Live Once\",\n",
    "    \"JK\": \"Just Kidding\",\n",
    "    \"TMI\": \"Too Much Information\",\n",
    "    \"WFH\": \"Work From Home\",\n",
    "    \"LMK\": \"Let Me Know\",\n",
    "    \"IKR\": \"I Know, Right?\",\n",
    "    \"RN\": \"Right Now\",\n",
    "    \"BFF\": \"Best Friends Forever\",\n",
    "    \"FOMO\": \"Fear Of Missing Out\",\n",
    "    \"GTG\": \"Got To Go\",\n",
    "    \"IDC\": \"I Don’t Care\",\n",
    "    \"ETA\": \"Estimated Time of Arrival\",\n",
    "    \"HMU\": \"Hit Me Up\",\n",
    "    \"WC\": \"Welcome (or Water Closet)\",\n",
    "    \"YOLO\": \"You Only Live Once\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ead9cb22-ca99-4da7-9100-33649c21bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacing_chat_abbreviations(text):\n",
    "    new_text = []\n",
    "    for word in text.split(' '):\n",
    "        if word.upper() in chat_abbreviations.keys():\n",
    "            new_text.append(chat_abbreviations[word.upper()])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51200c02-772e-4cf3-ae2d-99de7c1d1816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'do this work as soon as possible'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 'Do this work ASAP'\n",
    "replacing_chat_abbreviations(t).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad39fb3-45de-4f8d-a3d7-ffc3d7d691b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 5. Incorrect Spelling Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b016f74d-a51e-4c82-abca-bff6675d4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab5c9f4a-bc87-426b-a5bd-b9dbf4afd340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tomorrow I will definitely receive a message about their surprise plan.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "incorrect_text = 'Tomorow I wil definitly recieve a mesage about thier suprise plan.'\n",
    "\n",
    "textblobObj = TextBlob(incorrect_text)\n",
    "\n",
    "textblobObj.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b96b5-c71e-47ab-8463-6e46c8e79c6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 6. Stopwords Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "16fd0d3e-6a1a-41f9-8e0a-af95e40cbde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/de-\n",
      "[nltk_data]     ninja/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c426843a-a3ba-4d92-bf8b-e113efade7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9f4e319e-e9b6-4c7a-a52c-ad48a8854ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    for word in text.split(' '):\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_text.append(word)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90065feb-e09d-404e-96df-9306800f43fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'good', 'man']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"This is a good man\"\n",
    "\n",
    "remove_stopwords(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c7ede-66ef-4b2e-a0dd-c73bb7ce7969",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 7. Handling Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ecd26d9c-2597-4b2c-9668-bc5b6b001aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello ! Check out this  and !'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        r\"[\\U0001F600-\\U0001F64F]\"  # Emoticons\n",
    "        r\"|[\\U0001F300-\\U0001F5FF]\"  # Miscellaneous Symbols and Pictographs\n",
    "        r\"|[\\U0001F680-\\U0001F6FF]\"  # Transport and Map Symbols\n",
    "        r\"|[\\u2600-\\u26FF]\"          # Miscellaneous Symbols\n",
    "        r\"|[\\u2700-\\u27BF]\"          # Dingbats\n",
    "        r\"|[\\U0001F900-\\U0001F9FF]\"  # Supplemental Symbols and Pictographs\n",
    "        r\"|[\\U0001FA70-\\U0001FAFF]\"  # Symbols and Pictographs Extended\n",
    "        r\"|[\\U0001F1E6-\\U0001F1FF]\"  # Regional Indicator Symbols\n",
    "        r\"|[\\U0001F200-\\U0001F2FF]\"  # Enclosed Ideographic Supplement\n",
    "        r\"|[\\U0001F7E0-\\U0001F7FF]\"  # Geometric Shapes Extended\n",
    "        r\"|[\\U0001F100-\\U0001F1FF]\"  # Enclosed Alphanumeric Supplement\n",
    "        r\"|[\\U0001F3FB-\\U0001F3FF]\"  # Skin tone modifiers\n",
    "    )\n",
    "\n",
    "    return emoji_pattern.sub('', text)\n",
    "\n",
    "# Example usage\n",
    "text = \"Hello 🌍! Check out this 🚀 and 😂!\"\n",
    "remove_emojis(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e201e319-e94a-4e4c-99d0-1ebc5577c0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This movie is :fire:'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "emoji.demojize('This movie is 🔥')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a1bae9-276a-4a3a-a766-98469fa979af",
   "metadata": {},
   "source": [
    "#### 8. Tokenisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dcb269-cce3-47c8-88e7-762f42cc4890",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 8.a Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "257b44ca-cf81-475a-8134-6f45f686fd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My', 'name', 'is', 'Rohit']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word Tokenisation\n",
    "sentence = \"My name is Rohit\"\n",
    "sentence.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c3fd1d40-9123-48c3-8c8a-a40d9ca2efe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi, my name is Rohit', ' I am working as a data engineer']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence Tokernisation\n",
    "para = 'Hi, my name is Rohit. I am working as a data engineer'\n",
    "para.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "67e32f1b-469c-4ba2-8cb0-8a4f98a5f5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi!', 'my', 'name', 'is', 'Rohit!']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem with split function for tokenisation\n",
    "para = 'Hi! my name is Rohit!'\n",
    "para.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e781a-48c4-4d3d-bc97-7a5d15136aaf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 8.b Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b41de0d4-7285-4048-a4bc-620960ac078e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'I', 'am', 'Rohit']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenisation with Regex\n",
    "import re\n",
    "sentence = 'Hi I am Rohit!'\n",
    "tokens = re.findall(r\"[\\w']+\", sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694027fc-fcf4-43a5-aa5c-d93f3a3543c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 8.c NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d47090a4-b6dd-4417-b7dc-62b7964e5b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/de-ninja/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/de-\n",
      "[nltk_data]     ninja/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d1a411bf-5d84-49eb-bfe2-536513a11186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'My', 'name', 'is', 'Rohit', '!']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = \"Hi My name is Rohit!\"\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ae9de7c4-d178-46d6-9467-30f47dbf5094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As the sun dipped below the horizon, painting the sky in hues of orange and pink, the children laughed and played in the park.',\n",
       " 'Their joyful voices echoed through the air, blending with the soft rustling of leaves.',\n",
       " 'Meanwhile, parents sat on benches, sharing stories and watching the evening unfold peacefully.']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para = \"\"\"As the sun dipped below the horizon, painting the sky in hues of orange and pink, the children laughed and played in the park. Their joyful voices echoed through the air, blending with the soft rustling of leaves. Meanwhile, parents sat on benches, sharing stories and watching the evening unfold peacefully.\"\"\"\n",
    "sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28437fbb-0aa0-4571-8a8b-958178a55815",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 8.d Spacy (Good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b7f2a247-ae0f-4438-80e2-2b2b1a36b975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b95696f9-2c36-4e3f-83f2-b81fe7cc9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "npl = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a26521a0-4d83-4687-8460-829157110fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hi, I am Rohit!"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"Hi, I am Rohit!\"\n",
    "npl(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8ad8caf6-d98a-43b6-bea0-365a2b8e0bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy is better as it do the following things:\n",
    "# 1. Tokenization: The text is split into individual tokens (words, punctuation marks, etc.).\n",
    "# 2. Part-of-speech tagging (POS): Each token is assigned a part-of-speech label (e.g., noun, verb).\n",
    "# 3. Named Entity Recognition (NER): The model identifies named entities like person names, organizations, and locations.\n",
    "# 4. Dependency parsing: The relationships between tokens (which words are subjects, objects, etc.) are identified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245d5596-789f-47c0-9c3c-1a0f63edf4ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 9. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "722c157c-bce2-4b07-a7c0-eaeb0e235e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return ' '.join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c853e91d-28ee-45b0-8443-f44592a916b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"walks walk walked walking\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c1ddc07a-ccbc-4630-a6f1-b276bfe745df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'as the sun dip below the horizon, paint the sky in hue of orang and pink, the children laugh and play in the park. their joy voic echo through the air, blend with the soft rustl of leaves. meanwhile, parent sat on benches, share stori and watch the even unfold peacefully.'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para = 'As the sun dipped below the horizon, painting the sky in hues of orange and pink, the children laughed and played in the park. Their joyful voices echoed through the air, blending with the soft rustling of leaves. Meanwhile, parents sat on benches, sharing stories and watching the evening unfold peacefully.'\n",
    "stem_words(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "903e7e1c-cc22-4f6e-b73b-98776398a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometime Stemmed words are not readble it just remove the ed ing like that to create the root word, \n",
    "# which can be wrong sometimes \n",
    "# And words might not be readable by human "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d0e0e4-ff7b-4370-baec-0dad139fe575",
   "metadata": {},
   "source": [
    "#### 10. Lemmetisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "83e39828-15fa-4fa4-ba29-3e39c0ead805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/de-ninja/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to /home/de-ninja/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "wordnet_lemmetizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "73a4a9ea-4e88-42da-8098-77fab4bffda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                 | Lemma               \n",
      "As                   | As                  \n",
      "the                  | the                 \n",
      "sun                  | sun                 \n",
      "dipped               | dip                 \n",
      "below                | below               \n",
      "the                  | the                 \n",
      "horizon              | horizon             \n",
      "painting             | paint               \n",
      "the                  | the                 \n",
      "sky                  | sky                 \n",
      "in                   | in                  \n",
      "hues                 | hue                 \n",
      "of                   | of                  \n",
      "orange               | orange              \n",
      "and                  | and                 \n",
      "pink                 | pink                \n",
      "the                  | the                 \n",
      "children             | children            \n",
      "laughed              | laugh               \n",
      "and                  | and                 \n",
      "played               | play                \n",
      "in                   | in                  \n",
      "the                  | the                 \n",
      "park                 | park                \n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "sentence = 'As the sun dipped below the horizon, painting the sky in hues of orange and pink, the children laughed and played in the park.'\n",
    "puntuations = string.punctuation\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "\n",
    "for word in sentence_words:\n",
    "    if word in puntuations:\n",
    "        sentence_words.remove(word)\n",
    "\n",
    "print(\"{0:20} | {1:20}\".format('Word',\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print(\"{0:20} | {1:20}\".format(word, wordnet_lemmetizer.lemmatize(word, pos='v')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "554185bb-d6ff-47bf-ad4f-0b0f960deff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Lemmetization is better than Stemming but slower as compared to stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d22c350-7a34-435e-a00c-27c4a62d870a",
   "metadata": {},
   "source": [
    "#### Practice - Twitter Sentiment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5bf69a85-5c98-43be-bfd3-e05d1069732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/jp797498e/twitter-entity-sentiment-analysis?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 1.99M/1.99M [00:00<00:00, 2.15MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: /home/de-ninja/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jp797498e/twitter-entity-sentiment-analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "06ad0a32-c923-4830-afde-9ae0d0aac329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter_training.csv  twitter_validation.csv\n"
     ]
    }
   ],
   "source": [
    "!ls /home/de-ninja/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2dfe19d-d6d8-4cee-a70a-ea190546cbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sno</th>\n",
       "      <th>game</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sno         game sentiment  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "                                              review  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/de-ninja/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2'+'/twitter_training.csv', header=None, names = ['sno', 'game', 'sentiment', 'review'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c59099e4-396f-4a27-bc59-2b55ca0f1368",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a42ffc8a-80e2-4239-a8c1-809b5a45e851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sno</th>\n",
       "      <th>game</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sno         game sentiment  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "                                              review  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Removing HTML tags\n",
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile(r'<.*?>')\n",
    "    return pattern.sub(r'',text)\n",
    "\n",
    "df['review'] = df['review'].apply(remove_html_tags)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f7fc69d-ce18-455f-8791-ea9acc825e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sno</th>\n",
       "      <th>game</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sno         game sentiment  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "                                              review  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Renoving the urls\n",
    "def remove_urls(text):\n",
    "    https_pattern = re.compile(r'https?://\\S+')\n",
    "    http_pattern = re.compile(r'https?://\\S+')\n",
    "    text = http_pattern.sub(r'', text)\n",
    "    text = https_pattern.sub(r'', text)\n",
    "    return text\n",
    "\n",
    "df['review'] = df['review'].apply(remove_urls)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbe5bf10-0a8b-437d-85d0-61c94e77d21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Removing Punctuations\n",
    "import string \n",
    "punctuations = string.punctuation\n",
    "punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25d8e5d7-6ca0-445a-b4ff-1684165c4055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sno</th>\n",
       "      <th>game</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sno         game sentiment  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "                                              review  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you all  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def remove_punctuations_v1(text):\n",
    "    pattern = re.compile(r'[{0}]'.format(punctuations))\n",
    "    return pattern.sub(r'', text)\n",
    "\n",
    "df['review'] = df['review'].apply(remove_punctuations_v1) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d091c95f-d4cd-4b71-8a26-b62ff3f476eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Removing Chat Abbreviations\n",
    "chat_abbreviations = {\n",
    "    \"AFK\": \"Away From Keyboard\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"DM\": \"Direct Message\",\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"GG\": \"Good Game\",\n",
    "    \"GLHF\": \"Good Luck, Have Fun\",\n",
    "    \"IDK\": \"I Don’t Know\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"IMHO\": \"In My Humble Opinion\",\n",
    "    \"IRL\": \"In Real Life\",\n",
    "    \"LMAO\": \"Laughing My Ass Off\",\n",
    "    \"LOL\": \"Laugh Out Loud\",\n",
    "    \"NP\": \"No Problem\",\n",
    "    \"NSFW\": \"Not Safe For Work\",\n",
    "    \"OMG\": \"Oh My God\",\n",
    "    \"OMW\": \"On My Way\",\n",
    "    \"ROFL\": \"Rolling On Floor Laughing\",\n",
    "    \"SMH\": \"Shaking My Head\",\n",
    "    \"TBH\": \"To Be Honest\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"TY\": \"Thank You\",\n",
    "    \"YOLO\": \"You Only Live Once\",\n",
    "    \"JK\": \"Just Kidding\",\n",
    "    \"TMI\": \"Too Much Information\",\n",
    "    \"WFH\": \"Work From Home\",\n",
    "    \"LMK\": \"Let Me Know\",\n",
    "    \"IKR\": \"I Know, Right?\",\n",
    "    \"RN\": \"Right Now\",\n",
    "    \"BFF\": \"Best Friends Forever\",\n",
    "    \"FOMO\": \"Fear Of Missing Out\",\n",
    "    \"GTG\": \"Got To Go\",\n",
    "    \"IDC\": \"I Don’t Care\",\n",
    "    \"ETA\": \"Estimated Time of Arrival\",\n",
    "    \"HMU\": \"Hit Me Up\",\n",
    "    \"WC\": \"Welcome (or Water Closet)\",\n",
    "    \"YOLO\": \"You Only Live Once\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23b8f74f-a1c8-48f6-9fb7-eb81b58a6a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sno</th>\n",
       "      <th>game</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sno         game sentiment  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "                                              review  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you all  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_chat_abbreviations(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word.upper() in chat_abbreviations.keys():\n",
    "            new_text.append(chat_abbreviations[word.upper()])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    return ' '.join(new_text)\n",
    "\n",
    "df['review'] = df['review'].apply(remove_chat_abbreviations)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56eabd79-0929-462d-837a-9bd97aafb219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5. Handling the Incorrect Spellings\n",
    "from textblob import TextBlob\n",
    "def handling_incorrect_spellings(text):\n",
    "    textblobObj = TextBlob(text)\n",
    "    return textblobObj.correct().string\n",
    "\n",
    "# df['review'] = df['review'].apply(handling_incorrect_spellings)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c19a95a7-4009-48cc-8ea8-945938c5a4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Twitter_data').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15de7705-b86b-4fe7-9d1e-428d18127bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b756310-9340-42c2-8ce4-eb75f80df9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+---------+--------------------+\n",
      "| sno|       game|sentiment|              review|\n",
      "+----+-----------+---------+--------------------+\n",
      "|2401|Borderlands| Positive|in getting on bor...|\n",
      "|2401|Borderlands| Positive|I am coming to th...|\n",
      "|2401|Borderlands| Positive|in getting on bor...|\n",
      "|2401|Borderlands| Positive|in coming on bord...|\n",
      "|2401|Borderlands| Positive|in getting on bor...|\n",
      "+----+-----------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "handlling_spellings = udf(handling_incorrect_spellings)\n",
    "base = base.withColumn('review', handlling_spellings('review'))\n",
    "base.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3256bde5-aced-48c5-b895-1c6666d7c242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/de-\n",
      "[nltk_data]     ninja/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 6. Handlling Stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "en_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15f9d99b-874e-4cb9-b809-eeded5bfb808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+---------+--------------------+\n",
      "| sno|       game|sentiment|              review|\n",
      "+----+-----------+---------+--------------------+\n",
      "|2401|Borderlands| Positive|getting borderlan...|\n",
      "|2401|Borderlands| Positive|I coming borders ...|\n",
      "|2401|Borderlands| Positive|getting borderlan...|\n",
      "|2401|Borderlands| Positive|coming borderland...|\n",
      "|2401|Borderlands| Positive|getting borderlan...|\n",
      "+----+-----------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 8.35 ms, sys: 0 ns, total: 8.35 ms\n",
      "Wall time: 1.31 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# def remove_stopwords(text):\n",
    "#     new_text = []\n",
    "#     for word in text.split():\n",
    "#         if word not in en_stopwords:\n",
    "#             new_text.append(word)\n",
    "#     return new_text\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in text.split() if word not in en_stopwords])\n",
    "\n",
    "remove_stopwords_udf = udf(remove_stopwords)\n",
    "\n",
    "base_v2 = base.withColumn('review', remove_stopwords_udf('review'))\n",
    "base_v2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "23ba80c4-ca7f-424b-8d47-e1fa824dd823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+---------+--------------------+\n",
      "| sno|       game|sentiment|              review|\n",
      "+----+-----------+---------+--------------------+\n",
      "|2401|Borderlands| Positive|in getting on bor...|\n",
      "|2401|Borderlands| Positive|I am coming to th...|\n",
      "|2401|Borderlands| Positive|in getting on bor...|\n",
      "|2401|Borderlands| Positive|in coming on bord...|\n",
      "|2401|Borderlands| Positive|in getting on bor...|\n",
      "+----+-----------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 7. Handling Emojis\n",
    "import re\n",
    "\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        r\"[\\U0001F600-\\U0001F64F]\"  # Emoticons\n",
    "        r\"|[\\U0001F300-\\U0001F5FF]\"  # Miscellaneous Symbols and Pictographs\n",
    "        r\"|[\\U0001F680-\\U0001F6FF]\"  # Transport and Map Symbols\n",
    "        r\"|[\\u2600-\\u26FF]\"          # Miscellaneous Symbols\n",
    "        r\"|[\\u2700-\\u27BF]\"          # Dingbats\n",
    "        r\"|[\\U0001F900-\\U0001F9FF]\"  # Supplemental Symbols and Pictographs\n",
    "        r\"|[\\U0001FA70-\\U0001FAFF]\"  # Symbols and Pictographs Extended\n",
    "        r\"|[\\U0001F1E6-\\U0001F1FF]\"  # Regional Indicator Symbols\n",
    "        r\"|[\\U0001F200-\\U0001F2FF]\"  # Enclosed Ideographic Supplement\n",
    "        r\"|[\\U0001F7E0-\\U0001F7FF]\"  # Geometric Shapes Extended\n",
    "        r\"|[\\U0001F100-\\U0001F1FF]\"  # Enclosed Alphanumeric Supplement\n",
    "        r\"|[\\U0001F3FB-\\U0001F3FF]\"  # Skin tone modifiers\n",
    "    )\n",
    "\n",
    "    return emoji_pattern.sub('', text)\n",
    "\n",
    "removing_emojis_udf = udf(remove_emojis)\n",
    "base = base.withColumn('review', removing_emojis_udf('review'))\n",
    "base.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d01f2432-ba66-4e48-8eb3-55694992d928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+---------+--------------------+\n",
      "| sno|       game|sentiment|              review|\n",
      "+----+-----------+---------+--------------------+\n",
      "|2401|Borderlands| Positive|in getting on bor...|\n",
      "|2401|Borderlands| Positive|I am coming to th...|\n",
      "|2401|Borderlands| Positive|in getting on bor...|\n",
      "|2401|Borderlands| Positive|in coming on bord...|\n",
      "|2401|Borderlands| Positive|in getting on bor...|\n",
      "+----+-----------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "base.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39c22ff0-2d7b-4542-8d5b-b7a3a734fc22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 8. Tokenization\n",
    "# from pyspark.sql.types import *\n",
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# broadcast_nlp = spark.sparkContext.broadcast(nlp)\n",
    "\n",
    "# # Define a UDF for tokenization\n",
    "# def tokenize_text(text):\n",
    "#     nlp_model = broadcast_nlp.value\n",
    "#     doc = nlp_model(text)\n",
    "#     return doc\n",
    "\n",
    "# # Register the UDF\n",
    "# tokenize_udf = udf(tokenize_text, StringType())\n",
    "\n",
    "# base = base.withColumn('review_tokens', tokenize_udf('review'))\n",
    "# base.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bcec35e9-2ce5-470d-a4cf-8b98c7b8d423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/de-ninja/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/de-ninja/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 10. Lemmetization\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "wordnet_lemmetizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c47e495-3d2e-4789-a408-861d5baa451a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+---------+--------------------+\n",
      "| sno|       game|sentiment|              review|\n",
      "+----+-----------+---------+--------------------+\n",
      "|2401|Borderlands| Positive|in getting on bor...|\n",
      "|2401|Borderlands| Positive|I am coming to th...|\n",
      "|2401|Borderlands| Positive|in getting on bor...|\n",
      "|2401|Borderlands| Positive|in coming on bord...|\n",
      "|2401|Borderlands| Positive|in getting on bor...|\n",
      "+----+-----------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "def lemmetize_word(text):\n",
    "    words = text.split()\n",
    "    return ' '.join([wordnet_lemmetizer.lemmatize(word) for word in words])\n",
    "\n",
    "lemmitizer_udf = udf(lemmetize_word)\n",
    "\n",
    "base = base.withColumn('review', lemmitizer_udf('review'))\n",
    "base.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a259308f-bb30-4424-ab7d-188b26307064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+---------+-------------------------------------------------------+\n",
      "|sno |game       |sentiment|review                                                 |\n",
      "+----+-----------+---------+-------------------------------------------------------+\n",
      "|2401|Borderlands|Positive |in getting on borderland and i will murder you all     |\n",
      "|2401|Borderlands|Positive |I am coming to the border and I will kill you all      |\n",
      "|2401|Borderlands|Positive |in getting on borderland and i will kill you all       |\n",
      "|2401|Borderlands|Positive |in coming on borderland and i will murder you all      |\n",
      "|2401|Borderlands|Positive |in getting on borderland 2 and i will murder you me all|\n",
      "+----+-----------+---------+-------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "base.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f799ffc5-9e18-4ec2-9eb1-b21b19e28c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4284675-4fb6-4fcb-9b44-bfab0e799a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
